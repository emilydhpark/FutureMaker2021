{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gender Classifications of Facial Images - CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNprD+UueFcX9U2GpVgSgQL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlapark/FutureMaker2021/blob/main/Gender_Classifications_of_Facial_Images_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV_HDUn4FveS"
      },
      "source": [
        "# LINK: https://www.kaggle.com/thanaphatj/gender-classification-of-facial-images-cnn/data\n",
        "\n",
        "import os # accessing directory structure\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from  IPython.display import display\n",
        "import plotly.express as px\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, experimental, MaxPool2D, BatchNormalization\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy, binary_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau \n",
        "from tensorflow.data import Dataset\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.random import set_seed\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow import test\n",
        "import random\n",
        "\n",
        "# Set Seed\n",
        "np.random.seed(11)\n",
        "set_seed(11)\n",
        "random.seed(11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_ht1ZjnF0aZ"
      },
      "source": [
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "        \n",
        "age_gender_data = pd.read_csv(\"/kaggle/input/age-gender-and-ethnicity-face-data-csv/age_gender.csv\")\n",
        "age_gender_data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdoSWKINF00M"
      },
      "source": [
        "age_gender_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7ZHfi--F4Xz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nac1rX19F4Zy"
      },
      "source": [
        "sns.countplot(x='age', data=age_gender_data) #age distribution\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UbOyuqTF5TV"
      },
      "source": [
        "sns.countplot(x='gender', data=age_gender_data) #gender distribution\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZlvjIQlF7qO"
      },
      "source": [
        "\n",
        "# Select only person who has age more than 18 \n",
        "age_gender_data = age_gender_data[age_gender_data['age'] >= 18]\n",
        "sns.countplot(x='age', data=age_gender_data) #age distribution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcNIOpExF9RH"
      },
      "source": [
        "age_gender_data.reset_index(drop=True, inplace=True)\n",
        "age_gender_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTpe8LAjF-qq"
      },
      "source": [
        "age_gender_data.isnull().sum() # Check null data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLChzlhBGAPq"
      },
      "source": [
        "# Input image configuration\n",
        "num_pixels = len(age_gender_data['pixels'][0].split(' '))\n",
        "dimension = int(np.sqrt(num_pixels))\n",
        "img_width = dimension\n",
        "img_height = dimension\n",
        "\n",
        "print(\"Pixels: {}\".format(num_pixels))\n",
        "print(\"Width: {0}, Height: {1}\".format(img_width, img_height))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOyQ5EPkGByn"
      },
      "source": [
        "# Splitting dataset into X and y\n",
        "X_img = age_gender_data.iloc[:,4].copy()\n",
        "y_age = age_gender_data.iloc[:,0].copy()\n",
        "y_ethnicity = age_gender_data.iloc[:,1].copy()\n",
        "y_gender = age_gender_data.iloc[:,2].copy()\n",
        "\n",
        "# splitting the data into train and te sets.\n",
        "X_train, X_te, y_train, y_te = train_test_split(X_img,y_gender,test_size=0.3,random_state=11)\n",
        "# splitting 'te' set into validation and test set\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_te,y_te,test_size=0.15,random_state=11)\n",
        "\n",
        "def str_to_npArr(x):\n",
        "    '''\n",
        "    Function to convert pixel data (string) into numpy_array of pixels\n",
        "    '''\n",
        "    x = x.reset_index(drop=True)\n",
        "    x = x.apply(lambda x: np.array(x.split(), dtype=\"float32\")) #converting data to numpy array\n",
        "    return np.array([x[i].reshape(img_width, img_height, 1) for i in range(x.shape[0])])\n",
        "\n",
        "# Converting the string of pixels into image array for each of train, val and test set and normalization\n",
        "X_train = str_to_npArr(X_train)\n",
        "X_test = str_to_npArr(X_test)\n",
        "X_val = str_to_npArr(X_val)\n",
        "\n",
        "print(\"Traget: shape = (16593, 48, 48, 1), type = <class 'numpy.ndarray'>\")\n",
        "print(\"Current: shape = {}, type = {}\".format(X_train.shape, type(X_train)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1v911WxGELA"
      },
      "source": [
        "target_columns = ['gender', 'ethnicity', 'age']\n",
        "\n",
        "age_gender_data_preprocess = age_gender_data.drop('img_name', axis=1)\n",
        "y = age_gender_data_preprocess[target_columns]\n",
        "X = age_gender_data_preprocess.drop(target_columns, axis=1)\n",
        "\n",
        "print(X)\n",
        "print(\"--------------------------------------------------------\")\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kuYwi0CGFiR"
      },
      "source": [
        "X = X['pixels'].apply(lambda x: np.array(x.split(), dtype=\"float32\")) #converting data to numpy array\n",
        "X = np.array(X)/255.0 # normalization\n",
        "X = np.array([ X[i].reshape(48,48,1) for i in range(X.shape[0]) ])\n",
        "\n",
        "print(\"Traget: X Shape: {}\".format(X.shape))\n",
        "print(\"Current: X Shape: {}\".format(X.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caoeMInyGHHR"
      },
      "source": [
        "y_gender = np.array(y['gender'])\n",
        "y_ethnicity = np.array(y['ethnicity'])\n",
        "y_age = np.array(y['age'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar_YsUGcGIPF"
      },
      "source": [
        "rows = 20 # rows in subplots\n",
        "cols = 5 # columns in subplots\n",
        "samp = random.sample(range(X.shape[0]),rows*cols) #selecting 100 random samples\n",
        "x_samp = X[samp,:,:,:]\n",
        "y_samp_gender = y_gender[samp]\n",
        "y_samp_age = y_age[samp]\n",
        "    \n",
        "fig,ax = plt.subplots(rows,cols,figsize=(16,60))\n",
        "r = 0\n",
        "c = 0   \n",
        "\n",
        "for i in range(rows*cols):\n",
        "    aa = x_samp[i,:,:,:].reshape(48,48)\n",
        "    ax[r,c].axis(\"off\")\n",
        "    ax[r,c].imshow(aa,cmap=\"gray\")\n",
        "    ax[r,c].set_title(f\"Gender: {'Female' if y_samp_gender[i]==1 else 'Male'}, Age: {y_samp_age[i]}\")\n",
        "    c+=1\n",
        "    if c == cols:\n",
        "        c=0\n",
        "        r+=1\n",
        "        \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajkli1PNGKQu"
      },
      "source": [
        "train_data_gen = ImageDataGenerator(rotation_range=30,\n",
        "                                   width_shift_range=1,\n",
        "                                    brightness_range=[0.8,1.2],\n",
        "                                    zoom_range=[0.8,1.2],\n",
        "                                    rescale=1/255\n",
        "                                   )\n",
        "val_data_gen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "test_data_gen = ImageDataGenerator(rescale=1/255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDZyqabUGMVD"
      },
      "source": [
        "set_seed(11)\n",
        "random.seed(11)\n",
        "np.random.seed(11)\n",
        "\n",
        "val_data = val_data_gen.flow(X_val,y_val,\n",
        "                                   seed=11,shuffle=False)\n",
        "\n",
        "test_data = test_data_gen.flow(X_test,y_test,\n",
        "                                   seed=11,shuffle=False)\n",
        "fig,ax = plt.subplots(10,5,figsize=(15,25))\n",
        "for n in range(10):    \n",
        "    r = random.sample(range(X.shape[0]),1)[0]\n",
        "    ax[n,0].imshow(X[r].reshape(48,48),cmap=\"gray\")\n",
        "    ax[n,0].set_title(\"Original\")\n",
        "    ax[n,0].axis(\"off\")\n",
        "    for i in range(1,5):\n",
        "        ax[n,i].imshow(train_data_gen.random_transform(X[r]).reshape(48,48),cmap=\"gray\")\n",
        "        ax[n,i].set_title(\"Augmented\")\n",
        "        ax[n,i].axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EBH96YcGOXG"
      },
      "source": [
        "# Model configuration\n",
        "batch_size = 32\n",
        "img_width, img_height, img_num_channels = 48, 48, 1\n",
        "loss_function = sparse_categorical_crossentropy\n",
        "no_classes = 2\n",
        "no_epochs = 50\n",
        "optimizer = Adam()\n",
        "verbosity = 1\n",
        "num_folds = 10\n",
        "activation='softmax'\n",
        "\n",
        "# Determine shape of the data\n",
        "input_shape = (img_width, img_height, img_num_channels)\n",
        "input_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASJBCYH5GQNy"
      },
      "source": [
        "# Set Seed\n",
        "random.seed(11)\n",
        "set_seed(11)\n",
        "np.random.seed(11)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "# Define per-fold score containers\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(X, y_gender):\n",
        "    \n",
        "  # Set Seed\n",
        "  random.seed(11)\n",
        "  set_seed(11)\n",
        "  np.random.seed(11)\n",
        "  \n",
        "  # Define the model architecture\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(Conv2D(64, kernel_size=(3,3), input_shape=input_shape, activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "  model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "  model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(128, activation='softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss=loss_function,\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "    \n",
        "  early_stop = EarlyStopping(monitor=\"val_loss\",patience=5,mode=\"min\") # Ensure the model doesn't overfit\n",
        "  \n",
        "  # Set Seed\n",
        "  random.seed(11)\n",
        "  set_seed(11)\n",
        "  np.random.seed(11)\n",
        "    \n",
        "  # Fit data to model\n",
        "  history = model.fit(train_data_gen.flow(X[train], y_gender[train], seed=11),\n",
        "            callbacks=early_stop,\n",
        "            batch_size=batch_size,\n",
        "            epochs=no_epochs,\n",
        "            verbose=verbosity,\n",
        "            validation_data=train_data_gen.flow(X[test], y_gender[test],\n",
        "                                   seed=11))\n",
        "  \n",
        "  # Generate generalization metrics\n",
        "  fig = px.line(\n",
        "  history.history, y=['loss', 'val_loss'],\n",
        "  labels={'index': 'epoch', 'value': 'loss'}, \n",
        "  title='Training History')\n",
        "  fig.show()\n",
        "    \n",
        "  scores = model.evaluate(train_data_gen.flow(X[test], y_gender[test],\n",
        "                                   seed=11), verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "  \n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN0S9o60GTLB"
      },
      "source": [
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv_PEwiIGYc1"
      },
      "source": [
        "# Set Seed\n",
        "random.seed(11)\n",
        "set_seed(11)\n",
        "np.random.seed(11)\n",
        "  \n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "  \n",
        "model.add(Conv2D(64, kernel_size=(3,3), input_shape=input_shape, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=loss_function,\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "Final_train = np.append(X_train, X_val, axis=0)\n",
        "Final_val = np.append(y_train, y_val, axis=0)\n",
        "final_training_data = train_data_gen.flow(Final_train, Final_val,\n",
        "                                   seed=11)\n",
        "\n",
        "random.seed(11)\n",
        "set_seed(11)\n",
        "np.random.seed(11)\n",
        "final_model_history = model.fit(train_data_gen.flow(X, y_gender, seed=11),batch_size=32,epochs=20, validation_data=val_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsCzjtyXGayD"
      },
      "source": [
        "# Generate generalization metrics\n",
        "fig = px.line(\n",
        "final_model_history.history, y=['loss', 'val_loss'],\n",
        "labels={'index': 'epoch', 'value': 'val_loss'}, \n",
        "title='Training History')\n",
        "fig.show()\n",
        "\n",
        "\n",
        "# Generate generalization metrics\n",
        "fig = px.line(\n",
        "final_model_history.history, y=['accuracy', 'val_accuracy'],\n",
        "labels={'index': 'epoch', 'value': 'accuracy'}, \n",
        "title='Training History')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEgVhrvtGclJ"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH6ce1rPGetW"
      },
      "source": [
        "model.save(\"backup\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua8neASnGfyo"
      },
      "source": [
        "# Metrics\n",
        "model.evaluate(test_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trNHnXcyGhJy"
      },
      "source": [
        "y_pred = model.predict_classes(test_data)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPhm_a_iGijt"
      },
      "source": [
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, cmap='Greens', cbar=False, annot=True, fmt='d');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfRl1VE9GkAT"
      },
      "source": [
        "error_index = (y_test != y_pred)#finding error indices\n",
        "y_test_error = y_test[error_index]\n",
        "X_test_error = X_test[error_index]\n",
        "prediction_error = y_pred[error_index]\n",
        "rows=int(np.floor(sum(error_index)/3)) #rows in subplots\n",
        "cols=3 #columns in subplots\n",
        "x_samp = X_test_error\n",
        "y_samp = y_test_error\n",
        "\n",
        "fig,ax = plt.subplots(rows,cols,figsize=(15,50))\n",
        "r = 0\n",
        "c = 0\n",
        "for i in range((rows*cols)-1):\n",
        "    aa = x_samp[i].reshape(48,48)\n",
        "    ax[r,c].axis(\"off\")\n",
        "    ax[r,c].imshow(aa,cmap=\"gray\")\n",
        "    actual_lab = \"Female\" if y_samp.iloc[i]==1 else \"Male\"\n",
        "    pred_lab = \"Female\" if int(prediction_error[i])==1 else \"Male\"\n",
        "    ax[r,c].set_title(f'Actual: {actual_lab}\\nPred: {pred_lab}')\n",
        "    c+=1\n",
        "    if c == cols:\n",
        "        c=0\n",
        "        r+=1\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSXg_SjzGmGR"
      },
      "source": [
        "import cv2\n",
        "img = cv2.imread('../input/testset/mind-long.jpg',0)\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "img = cv2.resize(img, (48,48))\n",
        "img = np.reshape(img,[1,48,48,1])\n",
        "img_pixels = img.astype(\"float32\") / 255.0\n",
        "classes = model.predict_classes(img_pixels)\n",
        "\n",
        "mapper=['male','female']\n",
        "print(mapper[classes[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF8I_XsEGoN2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}